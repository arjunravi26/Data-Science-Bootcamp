{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X,y,W,b):\n",
    "    y_pred = np.dot(X,W) + b\n",
    "    n = X.shape[0]\n",
    "    cost= np.sum((y - y_pred) ** 2) / n\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.randint(low=1,high=100,size=10)\n",
    "y = X * 2 + 1\n",
    "W = 2\n",
    "b = 3\n",
    "compute_cost(X,y,W,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "45.22430289199999\n",
      "642.2104988046597\n",
      "9287.495437954803\n",
      "134484.69495597587\n",
      "1947535.3434678987\n",
      "28203335.6077077\n",
      "408428261.05479914\n",
      "5914678022.189467\n",
      "85653759820.61633\n",
      "1240399992172.1262\n",
      "17962925898613.156\n",
      "260131174520763.0\n",
      "3767104999457753.0\n",
      "5.4553554002451736e+16\n",
      "7.900205209907355e+17\n",
      "1.1440728931398742e+19\n",
      "1.6567959312955507e+20\n",
      "2.39929883350701e+21\n",
      "3.4745588057828204e+22\n",
      "5.031702898465842e+23\n",
      "7.286690332105453e+24\n",
      "1.0552263730075942e+26\n",
      "1.5281323173356552e+27\n",
      "2.2129738594666777e+28\n",
      "3.2047311918783e+29\n",
      "4.6409504424389504e+30\n",
      "6.720819850275983e+31\n",
      "9.732795042759793e+32\n",
      "1.4094604743866146e+34\n",
      "2.0411185277511334e+35\n",
      "2.9558578761437326e+36\n",
      "4.2805430773230525e+37\n",
      "6.198893791444025e+38\n",
      "8.976964731688711e+39\n",
      "1.3000044605573176e+41\n",
      "1.8826091535184218e+42\n",
      "2.7263115877248063e+43\n",
      "3.948124261199617e+44\n",
      "5.717499515483274e+45\n",
      "8.27983076186636e+46\n",
      "1.1990485921248695e+48\n",
      "1.736409315149523e+49\n",
      "2.5145914265199686e+50\n",
      "3.641520456703631e+51\n",
      "5.273489401394695e+52\n",
      "7.636834887314077e+53\n",
      "1.1059327640001139e+55\n",
      "1.6015630775527993e+56\n",
      "2.319313049468648e+57\n",
      "3.35872691923882e+58\n",
      "4.8639602664262894e+59\n",
      "7.043772846747322e+60\n",
      "1.020048133596874e+62\n",
      "1.4771887417336971e+63\n",
      "2.1391996189536195e+64\n",
      "3.0978945888529447e+65\n",
      "4.4862343834647206e+66\n",
      "6.496766873799029e+67\n",
      "9.408331398836807e+68\n",
      "1.3624730797609465e+70\n",
      "1.973073454133199e+71\n",
      "2.857318000065121e+72\n",
      "4.137841972580199e+73\n",
      "5.992240342046694e+74\n",
      "8.677698315883651e+75\n",
      "1.256666017434305e+77\n",
      "1.8198483306150587e+78\n",
      "2.6354241305928752e+79\n",
      "3.8165050522445674e+80\n",
      "5.526894379058278e+81\n",
      "8.003804805472723e+82\n",
      "1.1590757298861848e+84\n",
      "1.678522378122694e+85\n",
      "2.4307621160658079e+86\n",
      "3.520122544633019e+87\n",
      "5.097686296546746e+88\n",
      "7.382244580553264e+89\n",
      "1.0690641180495074e+91\n",
      "1.548171529715582e+92\n",
      "2.24199376347499e+93\n",
      "3.246756537619693e+94\n",
      "4.701809695597671e+95\n",
      "6.808953537927938e+96\n",
      "9.860426364144474e+97\n",
      "1.4279434797304144e+99\n",
      "2.0678848013298025e+100\n",
      "2.994619613640523e+101\n",
      "4.336676116886972e+102\n",
      "6.280183184906985e+103\n",
      "9.094684447936236e+104\n",
      "1.3170521109370841e+106\n",
      "1.9072968093109047e+107\n",
      "2.7620631625724144e+108\n",
      "3.999898115907738e+109\n",
      "5.792476129597855e+110\n",
      "8.388408589338901e+111\n",
      "1.2147723544711407e+113\n",
      "1.759179774650984e+114\n",
      "2.547566602211977e+115\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def gradient_descent(X,y,W,b):\n",
    "    learning_rate = 0.001\n",
    "    prev_cost = 0\n",
    "    for _ in range(100):\n",
    "        cost = compute_cost(X,y,W,b)\n",
    "        print(cost)\n",
    "        if cost >= prev_cost + 1:\n",
    "            cost = prev_cost\n",
    "            y_pred = np.dot(X,W) + b\n",
    "            error = y - y_pred\n",
    "            n = X.shape[0]\n",
    "            dw = np.dot(X.T,error) / n\n",
    "            db = np.sum(error) / n\n",
    "            W -= learning_rate * dw\n",
    "            b -= learning_rate * db\n",
    "        else:\n",
    "            break\n",
    "    return W,b\n",
    "X = np.random.randint(low=1,high=100,size=10).reshape(10,-1)\n",
    "y = X * 2 + 1\n",
    "W = np.array([[2]],dtype=np.float64)\n",
    "b = 3\n",
    "w,b = gradient_descent(X,y,W,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.68726346e+117])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((y - np.dot(X,w) ** 2) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([4,5,6])\n",
    "np.dot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([4,5,6])\n",
    "np.dot(b,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final predictions: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Actual values: [[171]\n",
      " [193]\n",
      " [189]\n",
      " [ 13]\n",
      " [105]\n",
      " [123]\n",
      " [ 35]\n",
      " [  9]\n",
      " [ 33]\n",
      " [ 71]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_19308\\3719336913.py:21: RuntimeWarning: invalid value encountered in subtract\n",
      "  W -= learning_rate * dw\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_descent(X, y, W, b):\n",
    "    learning_rate = 0.001  # Step size for gradient descent\n",
    "    num_iterations = 500  # Number of iterations\n",
    "    \n",
    "    n = X.shape[0]  # Number of samples\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        # Calculate predictions\n",
    "        y_pred = np.dot(X, W) + b  # Shape: (n, 1)\n",
    "        \n",
    "        # Compute the error\n",
    "        error = y - y_pred  # Shape: (n, 1)\n",
    "        \n",
    "        # Compute gradients\n",
    "        dw = -2 * np.dot(X.T, error) / n  # Shape: (features, 1)\n",
    "        db = -2 * np.sum(error) / n       # Scalar\n",
    "        \n",
    "        # Update weights and bias\n",
    "        W -= learning_rate * dw\n",
    "        b -= learning_rate * db\n",
    "    \n",
    "    # Print final predictions and target values\n",
    "    print(\"Final predictions:\", np.dot(X, W) + b)\n",
    "    print(\"Actual values:\", y)\n",
    "\n",
    "# Generate random data\n",
    "X = np.random.randint(low=1, high=100, size=10).reshape(-1, 1)  # Shape: (10, 1)\n",
    "y = 2 * X + 1  # Shape: (10, 1)\n",
    "\n",
    "# Initialize weights and bias\n",
    "W = np.array([[2.0]])  # Shape: (1, 1)\n",
    "b = 3.0  # Scalar\n",
    "\n",
    "# Run gradient descent\n",
    "gradient_descent(X, y, W, b)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
